{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6793e347-36c2-4dd1-9fc2-41ae956dcab6",
   "metadata": {},
   "source": [
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "   \n",
    "                                          \n",
    "                                          \n",
    "                                          \n",
    "                                          \n",
    "                                          \n",
    "#                                                 Regression with Abalone Data Set: Principal Components Regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#                                                        Gladys Murage\n",
    "\n",
    "#                              College of Business, Engineering, and  Technology, National University\n",
    "\n",
    "#                                         DDS8555 v1: PREDICTIVE ANALYSIS(3602869492)\n",
    "\n",
    "#                                                        Dr MOHAMED NABEEL\n",
    "\n",
    "#                                                            March 17, 2025\n",
    "\n",
    "\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6397b-3935-495c-adf2-b2dcdae8125a",
   "metadata": {},
   "source": [
    "# What is Principal Component Regression (PCR)?\n",
    "Principal Component Regression (PCR) is a technique that combines Principal Component Analysis (PCA) with linear regression. It is useful when you have multicollinearity (prediciting features are correlated) in your data or when you have more features than observations ( high dimensionality). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fff08c-cf42-4a5d-94a6-db4d4b20521e",
   "metadata": {},
   "source": [
    "## Step 1: Import Necessary Libraries and load the Kaggle data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9689dfe-cdb1-4b0a-a7d9-dcf9c742dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c2347-92f4-4f67-af0a-2c134a3bbf37",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the Data\n",
    "The target variable is in a column named Rings in the train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b39fb0d-4c7f-49b0-b8b1-35a9484ba704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = train_data.drop(columns=['Rings'])\n",
    "y = train_data['Rings']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a865be-d651-4dc2-b992-d417e4ae9d74",
   "metadata": {},
   "source": [
    "## Step 3: Find, convert categorical data and handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8936ffe7-d05e-4c75-b162-0c4a31ff1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "if len(categorical_cols) > 0:\n",
    "    encoder = OneHotEncoder(drop='first')  # Use drop='first' to avoid multicollinearity\n",
    "    encoded_cols = encoder.fit_transform(X[categorical_cols])\n",
    "    encoded_cols_df = pd.DataFrame(encoded_cols.toarray(), columns=encoder.get_feature_names_out(categorical_cols))\\\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded columns\n",
    "    X = X.drop(columns=categorical_cols)\n",
    "    X = pd.concat([X, encoded_cols_df], axis=1)\n",
    "\n",
    "# Handle missing values (if any)\n",
    "X = X.fillna(X.mean())  # Fill missing values with the mean of each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66484912-5d31-45b7-a700-3e26184e30ee",
   "metadata": {},
   "source": [
    "## Step 4: Split the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f456995-a02d-408e-966c-2a608fb73aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d34bd-ab75-45a4-93fb-ef0f2031569d",
   "metadata": {},
   "source": [
    "## Step 5: Standardize the data (Important for PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3e939eb-2a9f-40c9-a78d-e9c66f10b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data (important for PCA)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f944b9-b564-4479-ac49-c399249ca01b",
   "metadata": {},
   "source": [
    "## Step 6: Initialize PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "698c0c17-0d81-4201-a7e6-9a2b23780193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA and fit on the training data\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040fbbf1-d99c-46f5-9cce-6a407930bbdf",
   "metadata": {},
   "source": [
    "## Step 7: Initialize the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "043b1055-92dd-40c4-9c32-76bc1f8c213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35946108-f561-474a-9455-5410c920495d",
   "metadata": {},
   "source": [
    "## Step 8: Fir the model onto the PCA transformed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4691735e-b169-4dea-8f4a-75cc53ba2eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the PCA-transformed training data\n",
    "model.fit(X_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2b6a9-b080-4e1b-9c47-125b67e74320",
   "metadata": {},
   "source": [
    "## Step 9: Predict on the PCA-Transformed Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03a5610e-78cf-49e6-b1ef-ae8ebca4900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the PCA-transformed validation data\n",
    "y_val_pred = model.predict(X_val_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e53cb-c006-41bd-b543-1a2a178ff9a6",
   "metadata": {},
   "source": [
    "## Step 10: Calculate Root Mean Squared Logarithmic Error (RMSLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dd887c5-3019-4e05-a551-ad461ec9f3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Logarithmic Error (RMSLE) on Validation Set: 0.19474415852230692\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSLE\n",
    "def rmsle(y_true, y_pred):\n",
    "    # Ensure predictions and true values are non-negative\n",
    "    y_true = np.maximum(0, y_true)\n",
    "    y_pred = np.maximum(0, y_pred)\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "rmsle_score = rmsle(y_val, y_val_pred)\n",
    "print(f\"Root Mean Squared Logarithmic Error (RMSLE) on Validation Set: {rmsle_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe0a4a-a665-4f0e-81f7-65ec66ad4163",
   "metadata": {},
   "source": [
    "## Step 11: Preprocess the test data the same way as the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8920a1d8-9e6a-442a-8180-e829acec1419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1',\n",
      "       'Whole weight.2', 'Shell weight', 'Sex_I', 'Sex_M'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e3969161-fa54-488c-a792-c63e4c517aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1',\n",
      "       'Whole weight.2', 'Shell weight', 'Sex_I', 'Sex_M'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e7feea37-f661-494d-86ff-1bc956788ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train columns: Index(['id', 'Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1',\n",
      "       'Whole weight.2', 'Shell weight', 'Sex_I', 'Sex_M'],\n",
      "      dtype='object')\n",
      "test_data columns: Index(['id', 'Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1',\n",
      "       'Whole weight.2', 'Shell weight', 'Sex_I', 'Sex_M'],\n",
      "      dtype='object')\n",
      "Column 'Sex' not found in test_data. Skipping encoding.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Step 1: Verify column names\n",
    "print(\"X_train columns:\", X_train.columns)\n",
    "print(\"test_data columns:\", test_data.columns)\n",
    "\n",
    "# Step 2: Encode the 'Sex' column in test_data to match X_train\n",
    "if 'Sex' in test_data.columns:\n",
    "    # Initialize the OneHotEncoder with the same configuration used for X_train\n",
    "    encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "    # Fit the encoder on the unique values of 'Sex' in test_data\n",
    "    encoder.fit(test_data[['Sex']])\n",
    "\n",
    "    # Transform the 'Sex' column in test_data\n",
    "    encoded_test_data = encoder.transform(test_data[['Sex']])\n",
    "    encoded_column_names = encoder.get_feature_names_out(['Sex'])\n",
    "\n",
    "    # Add the encoded columns to test_data\n",
    "    test_data = pd.concat([test_data.drop(columns=['Sex']), \n",
    "                           pd.DataFrame(encoded_test_data, columns=encoded_column_names)], axis=1)\n",
    "\n",
    "    print(\"test_data after encoding:\")\n",
    "    print(test_data.head())\n",
    "else:\n",
    "    print(\"Column 'Sex' not found in test_data. Skipping encoding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb86551-0cbd-47be-aa62-7bd8b36f2027",
   "metadata": {},
   "source": [
    "## Step 12: Scale the data and apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e1a6f67d-abd2-4e26-9f05-78ac94fe2e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA-transformed test data:\n",
      "[[ 2.81787426  0.75995272  1.75863694  0.56075429]\n",
      " [ 1.76149812  1.07293501  1.77683515  0.2909738 ]\n",
      " [ 0.81503066  1.33888992  1.79161837  0.11091342]\n",
      " ...\n",
      " [ 0.65411004 -1.69066664  3.96499179  0.94741167]\n",
      " [ 3.74425065 -1.47592194  3.97260446 -0.34236667]\n",
      " [-1.80298474  0.08477942  4.0582052  -1.36234991]]\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Step 1: Fill missing values in numeric columns with the means\n",
    "numeric_cols = X_train.select_dtypes(include=['int', 'float']).columns\n",
    "X_train[numeric_cols] = X_train[numeric_cols].fillna(X_train[numeric_cols].mean())\n",
    "test_data[numeric_cols] = test_data[numeric_cols].fillna(test_data[numeric_cols].mean())\n",
    "\n",
    "# Step 2: Standardize numeric columns\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_cols])\n",
    "test_data_scaled = scaler.transform(test_data[numeric_cols])\n",
    "\n",
    "# Step 3: Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(test_data_scaled)\n",
    "\n",
    "# Display PCA-transformed test data\n",
    "print(\"PCA-transformed test data:\")\n",
    "print(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72597555-a372-4784-b949-0e51a24067ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.71702813 0.10382612 0.09994209 0.03428858]\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f442c4-4c34-46e3-b448-447a663a5f09",
   "metadata": {},
   "source": [
    "# Breaking down the Principal Component Analysis (PCA) results\n",
    "## 1. PCA-Transformed Test Data\n",
    "PCA (Principal Component Analysis) transforms the original features into a new set of uncorrelated features called principal components. Each row in the PCA-transformed test data corresponds to a sample in the test dataset, and each column corresponds to a principal component.\n",
    "\n",
    "### Example:\n",
    "For the first sample in the test data:\n",
    "\n",
    "\n",
    "[2.81787426  0.75995272  1.75863694  0.56075429]\n",
    "\n",
    "PC1: 2.81787426\n",
    "\n",
    "PC2: 0.75995272\n",
    "\n",
    "PC3: 1.75863694\n",
    "\n",
    "PC4: 0.56075429\n",
    "\n",
    "These values represent the coordinates of the sample in the new PCA space.\n",
    "\n",
    "## Key Points:\n",
    "Each principal component is a linear combination of the original features.\n",
    "\n",
    "The principal components are ordered by the amount of variance they explain in the data (PC1 explains the most variance, PC2 the second most, and so forth).\n",
    "\n",
    "The number of principal components is determined by the n_components parameter in PCA. In this case, 4 components were retained.\n",
    "\n",
    "## 2. Explained Variance Ratio\n",
    "The explained_variance_ratio_ attribute of PCA tells of the proportion of the dataset’s variance that is explained by each principal component.\n",
    "\n",
    "### Example:\n",
    "\n",
    "Explained variance ratio: [0.71702813 0.10382612 0.09994209 0.03428858]\n",
    "\n",
    "PC1: Explains 71.70% of the variance.\n",
    "\n",
    "PC2: Explains 10.38% of the variance.\n",
    "\n",
    "PC3: Explains 9.99% of the variance.\n",
    "\n",
    "PC4: Explains 3.43% of the variance.\n",
    "\n",
    "## Key Points:\n",
    "The sum of the explained variance ratios is 0.954 (71.70% + 10.38% + 9.99% + 3.43%), which means these 4 components explain 95.4% of the total variance in the dataset.\n",
    "\n",
    "This is consistent with the PCA configuration (n_components=0.95), which retains enough components to explain 95% of the variance.\n",
    "## 3. What Does This Mean for the PCA  Model?\n",
    "### Dimensionality Reduction:\n",
    "PCA reduces the number of features from the original dataset to 4 principal components while retaining 95.4% of the variance.\n",
    "\n",
    "This simplifies the dataset and can improve model performance by removing noise and redundancy.\n",
    "\n",
    "### Model Input:\n",
    "The PCA-transformed data (X_train_pca and X_test_pca) is used as input into the regression model next instead of the original features.\n",
    "\n",
    "This can help improve model performance, especially if the original dataset had many features or multicollinearity.\n",
    "\n",
    "### Interpretability:\n",
    "The principal components are not directly interpretable in terms of the original features, but they capture the most important patterns in the data.\n",
    "\n",
    "If interpretability is important, one can analyze the PCA loadings (the contribution of each original feature to the principal components).\n",
    "\n",
    "## 4. How to Use This Information\n",
    "## Check PCA Loadings (Optional):\n",
    "In order to  understand how the original features contribute to the principal components,one can examine the PCA loadings:\n",
    "\n",
    "# Get the PCA loadings (contribution of each original feature to the principal components)\n",
    "loadings = pca.components_\n",
    "\n",
    "# Create a DataFrame to visualize the loadings\n",
    "loadings_df = pd.DataFrame(loadings, columns=X_train.columns, index=[f\"PC{i+1}\" for i in range(loadings.shape[0])])\n",
    "print(\"PCA Loadings:\")\n",
    "print(loadings_df)\n",
    "Example Output:\n",
    "PCA Loadings:\n",
    "         Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  Shell weight  Sex_M\n",
    "PC1      0.45      0.40    0.12         0.70           0.30           0.11         0.14    0.10\n",
    "PC2     -0.30     -0.25    0.15        -0.20           0.40          -0.10         0.05   -0.20\n",
    "PC3      0.10      0.05   -0.20         0.10          -0.10           0.30        -0.15    0.25\n",
    "PC4     -0.05     -0.10    0.05        -0.05           0.10          -0.05         0.10   -0.15\n",
    "This shows how each original feature contributes to each principal component.\n",
    "\n",
    "## 5. Next Steps\n",
    "Use the PCA-transformed data (X_train_pca and X_test_pca) to train and evaluate the regression model.\n",
    "\n",
    "If the model performance is satisfactory, make predictions and save the results.\n",
    "\n",
    "If there is need to improve interpretability, analyze the PCA loadings to understand the contribution of the original features.\n",
    "\n",
    "# Summary\n",
    "## PCA-Transformed Test Data: \n",
    "The transformed data in the new PCA space, where each column represents a principal component.\n",
    "\n",
    "## Explained Variance Ratio: \n",
    "The proportion of variance explained by each principal component. In your case, 4 components explain 95.4% of the variance.\n",
    "\n",
    "## Use Case: \n",
    "PCA simplifies the dataset and can improve model performance by focusing on the most important patterns in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c048f3-56ee-46d3-924a-cffa785ff3d7",
   "metadata": {},
   "source": [
    "## Step 13: Using PCA for Regression Modeling:\n",
    "After transforming the data with PCA, one can use the PCA-transformed features (X_train_pca and X_test_pca) as input to the regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae08e202-c92c-4fa2-a3c9-3f6b2188bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA-transformed test data:\n",
      "[[-1.46827525 -0.72149524 -1.69242492  0.53369047]\n",
      " [-2.60735326 -0.74226829  1.09435236  0.37293396]\n",
      " [ 0.62934059  1.44702812  0.33091792  0.06617372]\n",
      " ...\n",
      " [-1.33170141  0.02032609  0.87375738 -1.26454658]\n",
      " [ 3.35038075  0.74416895 -0.25922538  0.56534709]\n",
      " [ 2.16683811  0.88457398  1.40949824  0.32056082]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example: Assume X and y are already loaded\n",
    "# X: Features, y: Target variable\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Standardize numeric columns\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Convert scaled data to NumPy arrays\n",
    "X_train_array = X_train_scaled\n",
    "X_test_array = X_test_scaled\n",
    "\n",
    "# Step 4: Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train_array)\n",
    "X_test_pca = pca.transform(X_test_array)\n",
    "\n",
    "# Step 5: Display PCA-transformed test data\n",
    "print(\"PCA-transformed test data:\")\n",
    "print(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2ffb6-6d26-45e4-8fd0-9acc7388c752",
   "metadata": {},
   "source": [
    "# Explanation of the Code\n",
    "### Load the Datasets:\n",
    "\n",
    "Load train.csv, test.csv, and sample_submission.csv into train_data, test_data, and sample_submission, respectively.\n",
    "\n",
    "### Separate Features and Target:\n",
    "\n",
    "For the training data, separate features (X_train) and target (y_train).\n",
    "\n",
    "### Encode Categorical Columns:\n",
    "\n",
    "If the 'Sex' column exists, encode it using OneHotEncoder for both training and test data.\n",
    "\n",
    "### Standardize the Data:\n",
    "\n",
    "Standardize the features using StandardScaler to ensure all features have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "### Apply PCA:\n",
    "\n",
    "Use PCA to reduce the dimensionality of the dataset while retaining 95% of the variance.\n",
    "\n",
    "### Train the Model:\n",
    "\n",
    "Train a linear regression model on the PCA-transformed training data.\n",
    "\n",
    "### Make Predictions:\n",
    "\n",
    "Use the trained model to make predictions on the PCA-transformed test data.\n",
    "\n",
    "### Calculate the RMSLE\n",
    "\n",
    "### Save Predictions:\n",
    "\n",
    "Save the predictions to the sample_submission.csv file in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ef3049c4-1485-4377-851d-b398e730b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE on validation set: 0.20025094970075333\n",
      "Predictions saved to submission5.csv\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "# Separate features and target variable in the training data\n",
    "X_train = train_data.drop(columns=[\"Rings\"])  # Replace \"Rings\" with the actual target column name\n",
    "y_train = train_data[\"Rings\"]\n",
    "\n",
    "# Step 1: Encode the 'Sex' column (if it exists)\n",
    "if 'Sex' in X_train.columns:\n",
    "    encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "    X_train_encoded = encoder.fit_transform(X_train[['Sex']])\n",
    "    encoded_column_names = encoder.get_feature_names_out(['Sex'])\n",
    "    X_train = pd.concat([X_train.drop(columns=['Sex']), \n",
    "                         pd.DataFrame(X_train_encoded, columns=encoded_column_names)], axis=1)\n",
    "\n",
    "    # Encode the 'Sex' column in the test data\n",
    "    X_test_encoded = encoder.transform(test_data[['Sex']])\n",
    "    test_data = pd.concat([test_data.drop(columns=['Sex']), \n",
    "                           pd.DataFrame(X_test_encoded, columns=encoded_column_names)], axis=1)\n",
    "\n",
    "# Step 2: Standardize the data (important for PCA)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "\n",
    "# Step 3: Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Step 4: Train a model on PCA-transformed training data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Step 5: Make predictions on PCA-transformed test data\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Step 6: Calculate RMSLE on the validation set\n",
    "rmsle_score = rmsle(y_val, y_val_pred)\n",
    "print(\"RMSLE on validation set:\", rmsle_score)\n",
    "\n",
    "# Step 7: Save predictions to the sample_submission file\n",
    "sample_submission[\"Rings\"] = y_pred  # Assuming 'Rings' is the target column\n",
    "sample_submission.to_csv(\"submission5.csv\", index=False)\n",
    "print(\"Predictions saved to submission5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c4ea9-60e3-4446-b6b3-7d7f60c3d3bf",
   "metadata": {},
   "source": [
    "# Breaking down the results of the RMSLE of the PCA on a Linear regression model\n",
    "The RMSLE (Root Mean Squared Logarithmic Error) value of 0.20025094970075333 on the validation set provides insight into the performance of the PCA-based linear regression model. \n",
    "## 1. What is RMSLE?\n",
    "RMSLE is a metric used to evaluate the accuracy of regression models. It measures the difference between the logarithm of the predicted values and the logarithm of the true values.\n",
    "\n",
    "### Key Properties of RMSLE:\n",
    "Penalizes Underestimation More Than Overestimation:\n",
    "RMSLE is asymmetric and penalizes underestimates more heavily than overestimates.\n",
    "\n",
    "### Logarithmic Scale:\n",
    "It works on a logarithmic scale, making it suitable for targets with a wide range of values (e.g., house prices, sales, etc.).\n",
    "\n",
    "### Non-Negative Values:\n",
    "Both true and predicted values must be non-negative.\n",
    "\n",
    "## 2. What Does RMSLE = 0.200 Mean?\n",
    "An RMSLE of 0.200 indicates the average logarithmic error between the predicted and true values. The interpretaation is aas follows: \n",
    "\n",
    "Lower RMSLE is Better:\n",
    "\n",
    "An RMSLE of 0 means perfect predictions (no error).\n",
    "\n",
    "An RMSLE of 0.200 suggests that, on average, the model’s predictions are off by approximately 0.200 on the logarithmic scale.\n",
    "\n",
    "### Relative Interpretation:\n",
    "\n",
    "If the true target values are in the range of 1 to 100, an RMSLE of 0.200 indicates that the model’s predictions are reasonably accurate but still have room for improvement.\n",
    "\n",
    "If the true target values are in the range of 1 to 10, an RMSLE of 0.200 suggests that the model’s predictions are less accurate.\n",
    "\n",
    "## 3. How Does PCA Affect the Model’s Performance?\n",
    "PCA (Principal Component Analysis) is used for dimensionality reduction. It transforms the original features into a smaller set of uncorrelated features (principal components) that capture the most variance in the data.\n",
    "\n",
    "### Impact of PCA on RMSLE:\n",
    "#### Improved Performance:\n",
    "\n",
    "If the original dataset has many irrelevant or redundant features, PCA can improve model performance by focusing on the most important patterns in the data.\n",
    "\n",
    "This can lead to a lower RMSLE.\n",
    "\n",
    "#### Potential Loss of Information:\n",
    "\n",
    "If PCA removes too much variance (e.g., by retaining too few components), the model may lose important information, leading to a higher RMSLE.\n",
    "\n",
    "#### Reduced Overfitting:\n",
    "\n",
    "PCA can help reduce overfitting by removing noise and redundancy in the data, which can improve generalization to unseen data.\n",
    "\n",
    "## 4. What Does RMSLE = 0.200 Mean for Your Model?\n",
    "### Model Performance:\n",
    "\n",
    "The model’s predictions are reasonably accurate but could be improved.\n",
    "\n",
    "An RMSLE of 0.200 suggests that the model is capturing some of the underlying patterns in the data but may still be missing some important relationships.\n",
    "\n",
    "### PCA’s Role:\n",
    "\n",
    "The PCA transformation likely helped reduce the dimensionality of the dataset and improved the model’s performance by focusing on the most important features.\n",
    "\n",
    "However, the RMSLE value indicates that there is still room for improvement, either by tuning the PCA parameters (e.g., increasing the number of components) or by using a more sophisticated model.\n",
    "\n",
    "## 5. How to Improve the Model’s Performance\n",
    "If trying to to reduce the RMSLE further, consider the following steps:\n",
    "\n",
    "### a) Tune PCA Parameters:\n",
    "Increase the number of principal components retained (e.g., n_components=0.99 to retain 99% of the variance).\n",
    "\n",
    "Experiment with different values of n_components to find the optimal balance between dimensionality reduction and information retention.\n",
    "\n",
    "### b) Feature Engineering:\n",
    "Create new features or transform existing ones to better capture the relationships in the data.\n",
    "\n",
    "For example, if the target variable has a logarithmic distribution, apply a logarithmic transformation to the target before training the model.\n",
    "\n",
    "### c) Try a Different Model:\n",
    "Linear regression may not be the best model for the data. Consider using more advanced models like:\n",
    "\n",
    "Random Forest Regressor\n",
    "\n",
    "Gradient Boosting Regressor (e.g., XGBoost, LightGBM, or CatBoost)\n",
    "\n",
    "Support Vector Regressor (SVR)\n",
    "\n",
    "### d) Hyperparameter Tuning:\n",
    "Use techniques like Grid Search or Randomized Search to find the best hyperparameters for the model.\n",
    "\n",
    "### e) Cross-Validation:\n",
    "Use cross-validation to get a more robust estimate of the model’s performance and reduce overfitting.\n",
    "\n",
    "## 6. Next Steps\n",
    "### Analyze Residuals:\n",
    "\n",
    "Plot the residuals (true values vs. predicted values) to identify patterns in the errors. This helps in understanding where the model is underperforming.\n",
    "\n",
    "### Feature Importance:\n",
    "\n",
    "If using a model that supports feature importance (e.g., Random Forest), analyze which features are most important for making predictions.\n",
    "\n",
    "### Experiment with Different Models:\n",
    "\n",
    "Try more advanced models and compare their RMSLE values to see if  better performance can be achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc24b79-c708-4f5b-8122-00169686b407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
